{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import os\n",
    "import sys\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from scipy.stats import spearmanr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of rows containing NaN values in filled_train is: 0\n",
      "The number of duplicates in the data is: 0\n"
     ]
    }
   ],
   "source": [
    "# read the data\n",
    "raw_X_train = pd.read_csv('./x_train.csv')\n",
    "raw_y_train = pd.read_csv('./y_train.csv')\n",
    "\n",
    "raw_X_train.head()\n",
    "\n",
    "raw_X_test = pd.read_csv('./x_test.csv')\n",
    "raw_X_test.head()\n",
    "\n",
    "# merge the X_train and y_train data\n",
    "raw_train = pd.merge(raw_X_train, raw_y_train, on='ID')\n",
    "raw_train.head()\n",
    "\n",
    "# sort data by ID and then by Date\n",
    "raw_train = raw_train.sort_values(['DAY_ID'])\n",
    "raw_train.head()\n",
    "\n",
    "# fill the NaN values with the mean of the column\n",
    "filled_train = raw_train.fillna(raw_train.mean())\n",
    "filled_train.head()\n",
    "\n",
    "# check if there are still NaN values\n",
    "print('The number of rows containing NaN values in filled_train is: {}'.format(filled_train.isnull().any(axis=1).sum()))\n",
    "\n",
    "# check duplicates in the data\n",
    "print('The number of duplicates in the data is: {}'.format(filled_train.duplicated().sum()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The shape of the raw_train_DE data is: (643, 19)\n",
      "The shape of the raw_train_FR data is: (851, 18)\n"
     ]
    }
   ],
   "source": [
    "# split the data by value of the column 'COUNTRY'\n",
    "raw_train_DE = filled_train[filled_train['COUNTRY']=='DE']\n",
    "raw_train_FR = filled_train[filled_train['COUNTRY']=='FR']\n",
    "\n",
    "# drop the columns which has name start with 'DE' in raw_train_FR\n",
    "raw_train_FR = raw_train_FR.drop(raw_train_FR.columns[raw_train_FR.columns.str.startswith('DE')], axis=1)\n",
    "\n",
    "# drop the columns of 'ID', 'COUNTRY' and 'DAY_ID'\n",
    "raw_train_DE = raw_train_DE.drop(['ID', 'COUNTRY', 'DAY_ID'], axis=1)\n",
    "# raw_train_FR.head()\n",
    "\n",
    "# drop the columns which has name start with 'FR' in raw_train_DE\n",
    "raw_train_DE = raw_train_DE.drop(raw_train_DE.columns[raw_train_DE.columns.str.startswith('FR')], axis=1)\n",
    "\n",
    "# drop the columns of 'ID', 'COUNTRY' and 'DAY_ID'\n",
    "raw_train_FR = raw_train_FR.drop(['ID', 'COUNTRY', 'DAY_ID'], axis=1)\n",
    "# raw_train_DE.head()\n",
    "\n",
    "# print the shape of the data\n",
    "print('The shape of the raw_train_DE data is: {}'.format(raw_train_DE.shape))\n",
    "print('The shape of the raw_train_FR data is: {}'.format(raw_train_FR.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The shape of the train_FR data is: (680, 18)\n",
      "The shape of the val_FR data is: (171, 18)\n",
      "The shape of the train_DE data is: (514, 19)\n",
      "The shape of the val_DE data is: (129, 19)\n"
     ]
    }
   ],
   "source": [
    "# split the data into train and validation sets\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train_FR, val_FR = train_test_split(raw_train_FR, test_size=0.2, random_state=42)\n",
    "\n",
    "train_DE, val_DE = train_test_split(raw_train_DE, test_size=0.2, random_state=42)\n",
    "\n",
    "# print the shape of the train and validation sets\n",
    "print('The shape of the train_FR data is: {}'.format(train_FR.shape))\n",
    "print('The shape of the val_FR data is: {}'.format(val_FR.shape))\n",
    "\n",
    "print('The shape of the train_DE data is: {}'.format(train_DE.shape))\n",
    "print('The shape of the val_DE data is: {}'.format(val_DE.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score on validation for 50 estimators : 19.08401338457116\n",
      "Score on train for 50 estimators : 100.0\n",
      "Score on validation for 53 estimators : 22.638109654563852\n",
      "Score on train for 53 estimators : 100.0\n",
      "Score on validation for 56 estimators : 17.912760554700462\n",
      "Score on train for 56 estimators : 100.0\n",
      "Score on validation for 59 estimators : 19.258144712821114\n",
      "Score on train for 59 estimators : 100.0\n",
      "Score on validation for 62 estimators : 16.74497848582345\n",
      "Score on train for 62 estimators : 100.0\n",
      "Score on validation for 65 estimators : 16.81296845976107\n",
      "Score on train for 65 estimators : 100.0\n",
      "Score on validation for 68 estimators : 19.09974108539237\n",
      "Score on train for 68 estimators : 100.0\n",
      "Score on validation for 71 estimators : 25.006938788866705\n",
      "Score on train for 71 estimators : 100.0\n",
      "Score on validation for 74 estimators : 19.09974108539237\n",
      "Score on train for 74 estimators : 100.0\n",
      "Score on validation for 77 estimators : 16.74497848582345\n",
      "Score on train for 77 estimators : 100.0\n",
      "Score on validation for 80 estimators : 17.934444100577924\n",
      "Score on train for 80 estimators : 100.0\n",
      "Score on validation for 83 estimators : 21.54499565529971\n",
      "Score on train for 83 estimators : 100.0\n",
      "Score on validation for 86 estimators : 19.09974108539237\n",
      "Score on train for 86 estimators : 100.0\n",
      "Score on validation for 89 estimators : 21.45450368496129\n",
      "Score on train for 89 estimators : 100.0\n",
      "Score on validation for 92 estimators : 20.27418005577816\n",
      "Score on train for 92 estimators : 100.0\n",
      "Score on validation for 95 estimators : 21.503046121456244\n",
      "Score on train for 95 estimators : 100.0\n",
      "Score on validation for 98 estimators : 23.809767370812004\n",
      "Score on train for 98 estimators : 100.0\n",
      "Score on validation for 101 estimators : 23.8220940687624\n",
      "Score on train for 101 estimators : 100.0\n",
      "Score on validation for 104 estimators : 26.16402888409913\n",
      "Score on train for 104 estimators : 100.0\n",
      "Score on validation for 107 estimators : 27.344883895281775\n",
      "Score on train for 107 estimators : 100.0\n",
      "Score on validation for 110 estimators : 26.171409029981874\n",
      "Score on train for 110 estimators : 100.0\n",
      "Score on validation for 113 estimators : 28.520569369521766\n",
      "Score on train for 113 estimators : 100.0\n",
      "Score on validation for 116 estimators : 27.344883895281775\n",
      "Score on train for 116 estimators : 100.0\n",
      "Score on validation for 119 estimators : 23.8220940687624\n",
      "Score on train for 119 estimators : 100.0\n",
      "Score on validation for 122 estimators : 24.989942431556813\n",
      "Score on train for 122 estimators : 100.0\n",
      "Score on validation for 125 estimators : 24.989942431556813\n",
      "Score on train for 125 estimators : 100.0\n",
      "Score on validation for 128 estimators : 26.171409029981874\n",
      "Score on train for 128 estimators : 100.0\n",
      "Score on validation for 131 estimators : 26.17133171914209\n",
      "Score on train for 131 estimators : 100.0\n",
      "Score on validation for 134 estimators : 29.693607985542737\n",
      "Score on train for 134 estimators : 100.0\n",
      "Score on validation for 137 estimators : 27.353912736669233\n",
      "Score on train for 137 estimators : 100.0\n",
      "Score on validation for 140 estimators : 27.353912736669233\n",
      "Score on train for 140 estimators : 100.0\n",
      "Score on validation for 143 estimators : 28.538162613999006\n",
      "Score on train for 143 estimators : 100.0\n",
      "Score on validation for 146 estimators : 27.353912736669233\n",
      "Score on train for 146 estimators : 100.0\n",
      "Score on validation for 149 estimators : 27.38112812571865\n",
      "Score on train for 149 estimators : 100.0\n",
      "Score on validation for 152 estimators : 27.353912736669233\n",
      "Score on train for 152 estimators : 100.0\n",
      "Score on validation for 155 estimators : 27.38112812571865\n",
      "Score on train for 155 estimators : 100.0\n",
      "Score on validation for 158 estimators : 26.193123783151425\n",
      "Score on train for 158 estimators : 100.0\n",
      "Score on validation for 161 estimators : 23.88714076468067\n",
      "Score on train for 161 estimators : 100.0\n",
      "Score on validation for 164 estimators : 22.659964841064177\n",
      "Score on train for 164 estimators : 100.0\n",
      "Score on validation for 167 estimators : 22.659964841064177\n",
      "Score on train for 167 estimators : 100.0\n",
      "Score on validation for 170 estimators : 23.809266284530214\n",
      "Score on train for 170 estimators : 100.0\n",
      "Best score on validation is 29.693607985542737 for 134 estimators\n"
     ]
    }
   ],
   "source": [
    "# For 'TARGET' in train_FR, change all positive values to 1 and negative values to -1 stored in 'train_FR_cl'\n",
    "train_FR_cl = train_FR.copy()\n",
    "train_FR_cl['TARGET'] = np.where(train_FR_cl['TARGET'] > 0, 1, -1)\n",
    "\n",
    "# For 'TARGET' in val_FR, change all positive values to 1 and negative values to -1 stored in 'val_FR_cl'\n",
    "val_FR_cl = val_FR.copy()\n",
    "val_FR_cl['TARGET'] = np.where(val_FR_cl['TARGET'] > 0, 1, -1)\n",
    "\n",
    "X_train_FR_cl = train_FR_cl.drop('TARGET', axis=1)\n",
    "y_train_FR_cl = train_FR_cl['TARGET']\n",
    "\n",
    "X_val_FR_cl = val_FR_cl.drop('TARGET', axis=1)\n",
    "y_val_FR_cl = val_FR_cl['TARGET']\n",
    "\n",
    "# Build Random Forest model\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "best_score = 0\n",
    "best_n = 0\n",
    "for i in range(50, 171, 3):\n",
    "\n",
    "    rf_model_FR = RandomForestClassifier(n_estimators=i, random_state=42)  # hyperparameters are tuned manually\n",
    "\n",
    "    rf_model_FR.fit(X_train_FR_cl, y_train_FR_cl)\n",
    "\n",
    "    preds_FR_cl = rf_model_FR.predict(X_val_FR_cl)\n",
    "\n",
    "    # evaluate the model using the Spearman correlation coefficient\n",
    "    score = spearmanr(preds_FR_cl, y_val_FR_cl).correlation * 100\n",
    "    print(\"Score on validation for {} estimators : {}\".format(i, score))\n",
    "    if score > best_score:\n",
    "        best_score = score\n",
    "        best_n = i\n",
    "\n",
    "    # evaluate based on the training set\n",
    "    train_preds_cl = rf_model_FR.predict(X_train_FR_cl)\n",
    "    train_score = spearmanr(train_preds_cl, y_train_FR_cl).correlation * 100\n",
    "    print(\"Score on train for {} estimators : {}\".format(i, train_score))\n",
    "\n",
    "print(\"Best score on validation is {} for {} estimators\".format(best_score, best_n))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score on validation for 50 estimators : 16.03182256509161\n",
      "Score on train for 50 estimators : 100.0\n",
      "Score on validation for 53 estimators : 19.28727619847363\n",
      "Score on train for 53 estimators : 100.0\n",
      "Score on validation for 56 estimators : 17.658400179005678\n",
      "Score on train for 56 estimators : 100.0\n",
      "Score on validation for 59 estimators : 17.814173613850176\n",
      "Score on train for 59 estimators : 100.0\n",
      "Score on validation for 62 estimators : 14.708729835219536\n",
      "Score on train for 62 estimators : 100.0\n",
      "Score on validation for 65 estimators : 19.633828302714363\n",
      "Score on train for 65 estimators : 100.0\n",
      "Score on validation for 68 estimators : 22.556595508348128\n",
      "Score on train for 68 estimators : 100.0\n",
      "Score on validation for 71 estimators : 22.741514009524366\n",
      "Score on train for 71 estimators : 100.0\n",
      "Score on validation for 74 estimators : 22.556595508348128\n",
      "Score on train for 74 estimators : 100.0\n",
      "Score on validation for 77 estimators : 19.633828302714363\n",
      "Score on train for 77 estimators : 100.0\n",
      "Score on validation for 80 estimators : 22.39346674729148\n",
      "Score on train for 80 estimators : 100.0\n",
      "Score on validation for 83 estimators : 22.948852389675228\n",
      "Score on train for 83 estimators : 100.0\n",
      "Score on validation for 86 estimators : 24.025061171111453\n",
      "Score on train for 86 estimators : 100.0\n",
      "Score on validation for 89 estimators : 24.199391484976278\n",
      "Score on train for 89 estimators : 100.0\n",
      "Score on validation for 92 estimators : 22.556595508348128\n",
      "Score on train for 92 estimators : 100.0\n",
      "Score on validation for 95 estimators : 19.83591657656471\n",
      "Score on train for 95 estimators : 100.0\n",
      "Score on validation for 98 estimators : 16.52614259590436\n",
      "Score on train for 98 estimators : 100.0\n",
      "Score on validation for 101 estimators : 19.83591657656471\n",
      "Score on train for 101 estimators : 100.0\n",
      "Score on validation for 104 estimators : 21.093200936158425\n",
      "Score on train for 104 estimators : 100.0\n",
      "Score on validation for 107 estimators : 22.948852389675228\n",
      "Score on train for 107 estimators : 100.0\n",
      "Score on validation for 110 estimators : 19.633828302714363\n",
      "Score on train for 110 estimators : 100.0\n",
      "Score on validation for 113 estimators : 15.067502410800387\n",
      "Score on train for 113 estimators : 100.0\n",
      "Score on validation for 116 estimators : 15.067502410800387\n",
      "Score on train for 116 estimators : 100.0\n",
      "Score on validation for 119 estimators : 16.72298076345419\n",
      "Score on train for 119 estimators : 100.0\n",
      "Score on validation for 122 estimators : 16.72298076345419\n",
      "Score on train for 122 estimators : 100.0\n",
      "Score on validation for 125 estimators : 15.269424839592755\n",
      "Score on train for 125 estimators : 100.0\n",
      "Score on validation for 128 estimators : 16.72298076345419\n",
      "Score on train for 128 estimators : 100.0\n",
      "Score on validation for 131 estimators : 15.269424839592755\n",
      "Score on train for 131 estimators : 100.0\n",
      "Score on validation for 134 estimators : 16.72298076345419\n",
      "Score on train for 134 estimators : 100.0\n",
      "Score on validation for 137 estimators : 12.152722617587271\n",
      "Score on train for 137 estimators : 100.0\n",
      "Score on validation for 140 estimators : 11.957569913211188\n",
      "Score on train for 140 estimators : 100.0\n",
      "Score on validation for 143 estimators : 10.49710913723315\n",
      "Score on train for 143 estimators : 100.0\n",
      "Score on validation for 146 estimators : 14.880819838522727\n",
      "Score on train for 146 estimators : 100.0\n",
      "Score on validation for 149 estimators : 12.152722617587271\n",
      "Score on train for 149 estimators : 100.0\n",
      "Score on validation for 152 estimators : 16.345707951086847\n",
      "Score on train for 152 estimators : 100.0\n",
      "Score on validation for 155 estimators : 16.52614259590436\n",
      "Score on train for 155 estimators : 100.0\n",
      "Score on validation for 158 estimators : 17.987010387340575\n",
      "Score on train for 158 estimators : 100.0\n",
      "Score on validation for 161 estimators : 15.067502410800387\n",
      "Score on train for 161 estimators : 100.0\n",
      "Score on validation for 164 estimators : 15.067502410800387\n",
      "Score on train for 164 estimators : 100.0\n",
      "Score on validation for 167 estimators : 15.067502410800387\n",
      "Score on train for 167 estimators : 100.0\n",
      "Score on validation for 170 estimators : 16.72298076345419\n",
      "Score on train for 170 estimators : 100.0\n",
      "Best score on validation is 24.199391484976278 for 89 estimators\n"
     ]
    }
   ],
   "source": [
    "# For 'TARGET' in train_FR, change all positive values to 1 and negative values to -1 stored in 'train_FR_cl'\n",
    "train_DE_cl = train_DE.copy()\n",
    "train_DE_cl['TARGET'] = np.where(train_DE_cl['TARGET'] > 0, 1, -1)\n",
    "\n",
    "# For 'TARGET' in val_FR, change all positive values to 1 and negative values to -1 stored in 'val_FR_cl'\n",
    "val_DE_cl = val_DE.copy()\n",
    "val_DE_cl['TARGET'] = np.where(val_DE_cl['TARGET'] > 0, 1, -1)\n",
    "\n",
    "X_train_DE_cl = train_DE_cl.drop('TARGET', axis=1)\n",
    "y_train_DE_cl = train_DE_cl['TARGET']\n",
    "\n",
    "X_val_DE_cl = val_DE_cl.drop('TARGET', axis=1)\n",
    "y_val_DE_cl = val_DE_cl['TARGET']\n",
    "\n",
    "# Build Random Forest model\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "best_score = 0\n",
    "best_n = 0\n",
    "for i in range(50, 171, 3):\n",
    "\n",
    "    rf_model_DE = RandomForestClassifier(n_estimators=i, random_state=42)  # hyperparameters are tuned manually\n",
    "\n",
    "    rf_model_DE.fit(X_train_DE_cl, y_train_DE_cl)\n",
    "\n",
    "    preds_DE_cl = rf_model_DE.predict(X_val_DE_cl)\n",
    "\n",
    "    # evaluate the model using the Spearman correlation coefficient\n",
    "    score = spearmanr(preds_DE_cl, y_val_DE_cl).correlation * 100\n",
    "    print(\"Score on validation for {} estimators : {}\".format(i, score))\n",
    "    if score > best_score:\n",
    "        best_score = score\n",
    "        best_n = i\n",
    "\n",
    "    # evaluate based on the training set\n",
    "    train_preds_cl = rf_model_DE.predict(X_train_DE_cl)\n",
    "    train_score = spearmanr(train_preds_cl, y_train_DE_cl).correlation * 100\n",
    "    print(\"Score on train for {} estimators : {}\".format(i, train_score))\n",
    "\n",
    "print(\"Best score on validation is {} for {} estimators\".format(best_score, best_n))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For 'TARGET' in train_FR, change all positive values to 1 and negative values to -1 stored in 'train_FR_cl'\n",
    "train_FR_cl = raw_train_FR.copy()\n",
    "train_FR_cl['TARGET'] = np.where(train_FR_cl['TARGET'] > 0, 1, -1)\n",
    "X_train_FR_cl = train_FR_cl.drop('TARGET', axis=1)\n",
    "y_train_FR_cl = train_FR_cl['TARGET']\n",
    "\n",
    "train_DE_cl = raw_train_DE.copy()\n",
    "train_DE_cl['TARGET'] = np.where(train_DE_cl['TARGET'] > 0, 1, -1)\n",
    "X_train_DE_cl = train_DE_cl.drop('TARGET', axis=1)\n",
    "y_train_DE_cl = train_DE_cl['TARGET']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-3 {color: black;background-color: white;}#sk-container-id-3 pre{padding: 0;}#sk-container-id-3 div.sk-toggleable {background-color: white;}#sk-container-id-3 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-3 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-3 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-3 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-3 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-3 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-3 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-3 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-3 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-3 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-3 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-3 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-3 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-3 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-3 div.sk-item {position: relative;z-index: 1;}#sk-container-id-3 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-3 div.sk-item::before, #sk-container-id-3 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-3 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-3 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-3 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-3 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-3 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-3 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-3 div.sk-label-container {text-align: center;}#sk-container-id-3 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-3 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-3\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomForestClassifier(n_estimators=89, random_state=42)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" checked><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier(n_estimators=89, random_state=42)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "RandomForestClassifier(n_estimators=89, random_state=42)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_rf_FR = RandomForestClassifier(n_estimators=best_n, random_state=42)\n",
    "best_rf_FR.fit(X_train_FR_cl, y_train_FR_cl)\n",
    "\n",
    "best_rf_DE = RandomForestClassifier(n_estimators=best_n, random_state=42)\n",
    "best_rf_DE.fit(X_train_DE_cl, y_train_DE_cl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read the test data\n",
    "raw_X_test = pd.read_csv('./x_test.csv')\n",
    "\n",
    "# fill the NaN values with the mean of the column\n",
    "filled_test = raw_X_test.fillna(raw_X_test.mean())\n",
    "\n",
    "# drop the columns which has name start with 'DE' in filled_test\n",
    "filled_test_FR = filled_test.drop(filled_test.columns[filled_test.columns.str.startswith('DE')], axis=1)\n",
    "\n",
    "# drop the columns which has name start with 'FR' in filled_test\n",
    "filled_test_DE = filled_test.drop(filled_test.columns[filled_test.columns.str.startswith('FR')], axis=1)\n",
    "\n",
    "# drop the columns of 'ID', 'COUNTRY' and 'DAY_ID'\n",
    "filled_test_FR = filled_test_FR.drop(['ID', 'COUNTRY', 'DAY_ID'], axis=1)\n",
    "# filled_test_FR.head()\n",
    "\n",
    "# drop the columns of 'ID', 'COUNTRY' and 'DAY_ID'\n",
    "filled_test_DE = filled_test_DE.drop(['ID', 'COUNTRY', 'DAY_ID'], axis=1)\n",
    "\n",
    "# predict the test data\n",
    "preds_FR = best_rf_FR.predict(filled_test_FR)\n",
    "preds_DE = best_rf_DE.predict(filled_test_DE)\n",
    "\n",
    "# create a dataframe with the ID and the predictions\n",
    "output_FR = pd.DataFrame({'ID': filled_test['ID'], 'TARGET': preds_FR})\n",
    "output_DE = pd.DataFrame({'ID': filled_test['ID'], 'TARGET': preds_DE})\n",
    "\n",
    "# merge the two dataframes\n",
    "output = pd.concat([output_FR, output_DE], axis=0)\n",
    "\n",
    "# save the dataframe as a csv file\n",
    "output.to_csv('./trading_new_hands1.csv', index=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
